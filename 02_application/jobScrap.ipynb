{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Application of Web Scraping using BeautifulSoup\n",
    "Following modules required\n",
    "```\n",
    "pip install beautifulsoup4\n",
    "pip install requests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to print out the result of a `requests.get()` we would get either a 200 or 400 based upon whether the\n",
    "HTTP request passed or failed respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"your-URL-here\"\n",
    "html_text = requests.get(url)\n",
    "print(html_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract the text, we have to use the `.text` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get(url).text\n",
    "print(html_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But by doing so, we would just get the source code of the entire page in extremely spaced formats as the\n",
    "spacing is where the image are located."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting Results using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posted few days ago\n"
     ]
    }
   ],
   "source": [
    "html_text = requests.get(url).text\n",
    "soup = BeautifulSoup(html_text, 'lxml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the box element which contains the data regarding each job and find the class and tag respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = soup.find('li', class_=\"clearfix job-bx wht-shd-bx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting all the information of each HTML card, we would need to find individual\n",
    "company names which can be done using the `.find()` method.   \n",
    "  \n",
    "This works because `bs4` returns a `bs4.element.Tag` when find method is used.  \n",
    "  \n",
    "If `find_all()` method is used then the returned datatyps is `bs4.element.ResultSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove all the unnecessary whitespaces using the replace method.\n",
    "company_name = job.find('h3', class_ = 'joblist-comp-name').text.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same to find the skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = job.find('span', class_ = 'srp-skills').text.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take some different action and manage `<span>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Posted few days ago'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_date = job.find('span', class_ = 'sim-posted').span.text\n",
    "published_date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the results for Company Name and Required Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: \n",
      "SuryaInformaticsSolutionsPvt.Ltd.\n",
      "\n",
      " \n",
      "Required Skills: \n",
      "python,webtechnologies,linux,mobile,mysql,angularjs,javascript\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Company Name: {company_name}\n",
    "Required Skills: {skills}\n",
    "''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have solved each individual problem by itself. Let us scrape the entire webpage using the `find_all()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: SuryaInformaticsSolutionsPvt.Ltd.\n",
      "Required Skills: python,webtechnologies,linux,mobile,mysql,angularjs,javascript\n",
      "\n",
      "Company Name: PerfiosSoftware\n",
      "Required Skills: python,java,scala\n",
      "\n",
      "Company Name: GSLAB\n",
      "Required Skills: rest,python,linux,mysql,docker\n",
      "\n",
      "Company Name: COGNITERTECHNOLOGIES\n",
      "Required Skills: c#,python,rdbms,oracle,sql\n",
      "\n",
      "Company Name: IvanInfotechPvt.Ltd.\n",
      "Required Skills: rest,python,security,debugging\n",
      "\n",
      "Company Name: TriadssTechSolutions\n",
      "Required Skills: python,django,html5,javascript\n",
      "\n",
      "Company Name: qualitythought\n",
      "Required Skills: rest,python,django,informationtechnology\n",
      "\n",
      "Company Name: GEMINISOFTWARESOLUTIONS\n",
      "Required Skills: python,docker,django,git,linux\n",
      "\n",
      "Company Name: eastindiasecuritiesltd.\n",
      "Required Skills: python,hadoop,machinelearning\n",
      "\n",
      "Company Name: JobsLoConsultants\n",
      "Required Skills: python,linux,windows,sql\n",
      "\n",
      "Company Name: sjainventures\n",
      "Required Skills: python,webdeveloper,webservices\n",
      "\n",
      "Company Name: arttechnologyandsoftwareindiapvtltd\n",
      "Required Skills: rest,python,database,django,api\n",
      "\n",
      "Company Name: TECHNOPARKTRIVANDRUM\n",
      "Required Skills: storage,database,debugging,mysql,mongodb,python\n",
      "\n",
      "Company Name: WingGlobalITServices\n",
      "Required Skills: springboot,python,java,django,jpa,hibernate\n",
      "\n",
      "Company Name: systango\n",
      "Required Skills: python,django,javascript,webprogramming\n",
      "\n",
      "Company Name: TandAHRSolutions\n",
      "Required Skills: Python,Django,Flask,unittesting\n",
      "\n",
      "Company Name: TandAHRSolutions\n",
      "Required Skills: python,git,django,GITHub\n",
      "\n",
      "Company Name: TandAHRSolutions\n",
      "Required Skills: Python,Django,Flask,GITHub\n",
      "\n",
      "Company Name: youngmindstechnologysolutionspvtltd\n",
      "Required Skills: python,html5,storage,javascript,security,django\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs = soup.find_all('li', class_=\"clearfix job-bx wht-shd-bx\")\n",
    "\n",
    "for job in jobs:\n",
    "\n",
    "    # Gathering the published date\n",
    "    published_date = job.find('span', class_ = 'sim-posted').span.text\n",
    "    # Taking only the recent jobs - \"Posted few days ago\"\n",
    "    if 'few' in published_date:\n",
    "\n",
    "        # Fetching the details\n",
    "        company_name = job.find('h3', class_ = 'joblist-comp-name').text.replace(' ', '')\n",
    "        skills = job.find('span', class_ = 'srp-skills').text.replace(' ', '')\n",
    "    \n",
    "        # Printing out the details for everyjob profile \"HTML card\"\n",
    "        print(f\"Company Name: {company_name.strip()}\")\n",
    "        print(f\"Required Skills: {skills.strip()}\")\n",
    "        print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
